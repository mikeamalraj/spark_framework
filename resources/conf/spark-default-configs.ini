[DEFAULT]
spark.eventlog.enable=True
spark.hadoop.hive.exec.dynamic.partition=True
spark.hadoop.hive.exec.dynamic.partition.mode=nonstrict
spark.sql.sources.partitionOverwriteMode=dynamic
spark.sql.inMemoryColumnarStorage.compressed=True
spark.sql.execution.arrow.pyspark.enabled=True
spark.sql.execution.arrow.pyspark.fallback.enabled=True
[LOCAL]
spark.jars=file:///D:/Spark/jars/mysql-connector-java-8.0.30.jar
spark.local.dir=C:/tmp
spark.sql.shuffle.partitions=20
spark.driver.memory=10g
spark.driver.host=localhost
spark.local.jdbc.url=jdbc:mysql://localhost:3306
spark.local.jdbc.driver=com.mysql.cj.jdbc.Driver
spark.local.db.username=root
spark.local.db.password=
[TEST]
spark.sql.shuffle.partitions=50
[UAT]
[PROD]
